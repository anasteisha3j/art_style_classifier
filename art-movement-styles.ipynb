{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":4804396,"sourceType":"datasetVersion","datasetId":2779739}],"dockerImageVersionId":31192,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import kagglehub\n\n# Download latest version\npath = kagglehub.dataset_download(\"sivarazadi/wikiart-art-movementsstyles\")\n\nprint(\"Path to dataset files:\", path)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T13:15:23.251059Z","iopub.execute_input":"2025-11-17T13:15:23.251320Z","iopub.status.idle":"2025-11-17T13:19:01.587799Z","shell.execute_reply.started":"2025-11-17T13:15:23.251292Z","shell.execute_reply":"2025-11-17T13:19:01.586796Z"}},"outputs":[{"name":"stdout","text":"Mounting files to /kaggle/input/wikiart-art-movementsstyles...\nPath to dataset files: /kaggle/input/wikiart-art-movementsstyles\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.models import Model\nimport matplotlib.pyplot as plt\n\nIMG_SIZE = 224\nBATCH_SIZE = 32\n\ndata_dir = \"/kaggle/input/wikiart-art-movementsstyles\"\n\ndatagen = ImageDataGenerator(\n    rescale=1./255,\n    validation_split=0.2\n)\n\ntrain_data = datagen.flow_from_directory(\n    data_dir,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode=\"categorical\",\n    subset=\"training\"\n)\n\nval_data = datagen.flow_from_directory(\n    data_dir,\n    target_size=(IMG_SIZE, IMG_SIZE),\n    batch_size=BATCH_SIZE,\n    class_mode=\"categorical\",\n    subset=\"validation\"\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-17T14:17:07.518749Z","iopub.execute_input":"2025-11-17T14:17:07.519054Z","iopub.status.idle":"2025-11-17T14:17:09.871728Z","shell.execute_reply.started":"2025-11-17T14:17:07.519035Z","shell.execute_reply":"2025-11-17T14:17:09.870629Z"}},"outputs":[{"name":"stdout","text":"Found 34004 images belonging to 13 classes.\nFound 8496 images belonging to 13 classes.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"base = MobileNetV2(\n    weights=None,          \n    include_top=False,\n    input_shape=(IMG_SIZE, IMG_SIZE, 3)\n)\n\nx = GlobalAveragePooling2D()(base.output)\nx = Dense(256, activation='relu')(x)\noutput = Dense(train_data.num_classes, activation='softmax')(x)\n\nmodel = Model(base.input, output)\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n\nmodel.summary()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"history = model.fit(\n    train_data,\n    validation_data=val_data,\n    epochs=3\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}